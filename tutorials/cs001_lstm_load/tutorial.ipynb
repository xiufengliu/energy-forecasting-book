{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial CS001: Load Forecasting with LSTM\n",
    "\n",
    "This tutorial demonstrates how to implement a Long Short-Term Memory (LSTM) network for short-term load forecasting. You will learn how to:\n",
    "1. Preprocess energy time series data.\n",
    "2. Build and train an LSTM model using PyTorch.\n",
    "3. Evaluate model performance using standard metrics.\n",
    "4. Visualize forecast results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.abspath('../../src'))\n",
    "\n",
    "from models.rnn import LSTMModel\n",
    "from preprocessing.pipeline import DataPipeline\n",
    "from utils.metrics import evaluate_all\n",
    "from utils.plotting import plot_forecast, set_style\n",
    "from utils.trainer import Trainer\n",
    "\n",
    "set_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "We use a public electricity load dataset (Dataset A) for this tutorial. First, we download/generate the data and apply a standard preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.download import download_public_dataset\n",
    "\n",
    "# Ensure project root is in path for download script\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "data_path = download_public_dataset('D001', save_dir='../../data/raw')\n",
    "df = pd.read_csv(data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = DataPipeline(method='standard')\n",
    "df = pipeline.add_calendar_features(df)\n",
    "\n",
    "# Split data temporally (no leaks!)\n",
    "train_df, val_df, test_df = pipeline.split_data(df)\n",
    "\n",
    "# Scale target\n",
    "target_col = 'load'\n",
    "train_scaled = pipeline.fit_transform(train_df, [target_col])\n",
    "val_scaled = pipeline.transform(val_df, [target_col])\n",
    "test_scaled = pipeline.transform(test_df, [target_col])\n",
    "\n",
    "# Create windowed sequences (X, y)\n",
    "WINDOW_SIZE = 24  # Look back 24 hours\n",
    "X_train, y_train = pipeline.create_sequences(train_scaled, WINDOW_SIZE)\n",
    "X_val, y_val = pipeline.create_sequences(val_scaled, WINDOW_SIZE)\n",
    "X_test, y_test = pipeline.create_sequences(test_scaled, WINDOW_SIZE)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).float()), batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).float()), batch_size=64)\n",
    "test_loader = DataLoader(TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).float()), batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Implementation\n",
    "\n",
    "We use a 2-layer LSTM with 64 hidden units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1  # only load\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = torch.nn.MSELoss()\n",
    "trainer = Trainer(model, criterion, patience=5)\n",
    "\n",
    "# Train for a few epochs for demonstration\n",
    "trainer.train(train_loader, val_loader, epochs=10, save_path='lstm_best.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation\n",
    "\n",
    "We evaluate the model on the held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_scaled = trainer.predict(test_loader)\n",
    "\n",
    "# Inverse transform to get actual MW values\n",
    "y_pred = pipeline.scaler.inverse_transform(y_pred_scaled)\n",
    "y_true = pipeline.scaler.inverse_transform(y_test)\n",
    "\n",
    "metrics = evaluate_all(y_true, y_pred)\n",
    "print(\"Test Metrics:\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization\n",
    "\n",
    "Visualizing the results for the first 168 hours (one week) of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(y_true[:168], y_pred[:168], title=\"LSTM Load Forecast (One Week)\", ylabel=\"Load (MW)\", save_path='../../figures/cs001_lstm_forecast.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
